/* SimpleApp.scala */
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf

object Q2 {
  def main(args: Array[String]) {
    val textFile = "/user/hue/review3.csv"  // ran this code on Horton Works sandbox VM
    val conf = new SparkConf().setAppName("Q2")
    val sc = new SparkContext(conf)
    val logData = sc.textFile(textFile)
    val busRatings = sc.textFile(textFile).map { 
	  line =>
      val fields = line.split("::")
	    (fields(2), fields(20).toDouble)
    }

	val filterbusRatings = busRatings.filter(data => data._1 !="NaN")
    val busAvgRatings = filterbusRatings.groupByKey().map(data => { val avg = data._2.sum / data._2.size; (avg,data._1)})
    
	val result = busAvgRatings.sortByKey(false,1).take(10)
    result.foreach{
		case(key,value) =>
			println(value,key)
	}
  }
}